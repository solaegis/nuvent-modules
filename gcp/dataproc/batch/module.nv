variables:
  batch_id:
    type: string
    description: "The ID to use for the batch, which will become the final component of the batch's resource name. This value must be 4-63 characters. Valid characters are /[a-z][0-9]-/."
    default: null
  id:
    type: string
    description: "Optional property for Batch"
    default: null
  labels:
    type: object
    description: "The labels to associate with this batch.   **Note**: This field is non-authoritative, and will only manage the labels present in your configuration. Please refer to the field 'effective_labels' for all of the labels present on the resource."
    default: null
  location:
    type: string
    description: "The location in which the batch will be created in."
    default: null
  project:
    type: string
    description: "Optional property for Batch"
    default: null
  environment_config:
    type: list
    description: "Nested block: environment_config"
    default: []
  pyspark_batch:
    type: list
    description: "Nested block: pyspark_batch"
    default: []
  runtime_config:
    type: list
    description: "Nested block: runtime_config"
    default: []
  spark_batch:
    type: list
    description: "Nested block: spark_batch"
    default: []
  spark_r_batch:
    type: list
    description: "Nested block: spark_r_batch"
    default: []
  spark_sql_batch:
    type: list
    description: "Nested block: spark_sql_batch"
    default: []
  timeouts:
    type: list
    description: "Nested block: timeouts"
    default: []

resources:
  main:
    type: gcp:dataproc:Batch
    properties:
      batch_id: ${var.batch_id}
      id: ${var.id}
      labels: ${var.labels}
      location: ${var.location}
      project: ${var.project}
      dynamic:
        environment_config:
          for_each: ${var.environment_config}
          content:
            execution_config: ${each.value.execution_config}
            peripherals_config: ${each.value.peripherals_config}
        pyspark_batch:
          for_each: ${var.pyspark_batch}
          content:
            archive_uris: ${each.value.archive_uris}
            args: ${each.value.args}
            file_uris: ${each.value.file_uris}
            jar_file_uris: ${each.value.jar_file_uris}
            main_python_file_uri: ${each.value.main_python_file_uri}
            python_file_uris: ${each.value.python_file_uris}
        runtime_config:
          for_each: ${var.runtime_config}
          content:
            cohort: ${each.value.cohort}
            container_image: ${each.value.container_image}
            effective_properties: ${each.value.effective_properties}
            properties: ${each.value.properties}
            version: ${each.value.version}
            autotuning_config: ${each.value.autotuning_config}
        spark_batch:
          for_each: ${var.spark_batch}
          content:
            archive_uris: ${each.value.archive_uris}
            args: ${each.value.args}
            file_uris: ${each.value.file_uris}
            jar_file_uris: ${each.value.jar_file_uris}
            main_class: ${each.value.main_class}
            main_jar_file_uri: ${each.value.main_jar_file_uri}
        spark_r_batch:
          for_each: ${var.spark_r_batch}
          content:
            archive_uris: ${each.value.archive_uris}
            args: ${each.value.args}
            file_uris: ${each.value.file_uris}
            main_r_file_uri: ${each.value.main_r_file_uri}
        spark_sql_batch:
          for_each: ${var.spark_sql_batch}
          content:
            jar_file_uris: ${each.value.jar_file_uris}
            query_file_uri: ${each.value.query_file_uri}
            query_variables: ${each.value.query_variables}
        timeouts:
          for_each: ${var.timeouts}
          content:
            create: ${each.value.create}
            delete: ${each.value.delete}
            update: ${each.value.update}
